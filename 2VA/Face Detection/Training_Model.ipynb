{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c82c9f0-55bc-4d73-9bff-c4c79b554075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                       \n",
    "import numpy as np                       \n",
    "import tensorflow as tf                       \n",
    "from keras.models import Sequential      \n",
    "\n",
    "from keras.preprocessing import image            \n",
    "from keras.preprocessing.image import ImageDataGenerator  \n",
    "\n",
    "from tensorflow.keras.optimizers import Adam  \n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Dropout     \n",
    "from keras.utils import np_utils  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ce07495-5df2-42bc-ac17-10cdd360e139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       emotion                                             pixels        Usage\n",
      "0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...     Training\n",
      "1            0  151 150 147 155 148 133 111 140 170 174 182 15...     Training\n",
      "2            2  231 212 156 164 174 138 161 173 182 200 106 38...     Training\n",
      "3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...     Training\n",
      "4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...     Training\n",
      "...        ...                                                ...          ...\n",
      "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
      "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n",
      "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n",
      "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n",
      "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest\n",
      "\n",
      "[35887 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "emotion_data = pd.read_csv('../data_csv/fer2013/fer2013.csv')\n",
    "print(emotion_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c89c5f-1cea-40b1-8034-b6f2347638c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = [], [], [], []   \n",
    "\n",
    "for index, row in emotion_data.iterrows():    \n",
    "    k = row['pixels'].split(\" \")       \n",
    "    if row['Usage'] == 'Training':    \n",
    "        X_train.append(np.array(k,'float32'))   \n",
    "        y_train.append(row['emotion'])\n",
    "    elif row['Usage'] == 'PublicTest':\n",
    "        X_test.append(np.array(k,'float32'))\n",
    "        y_test.append(row['emotion'])\n",
    "\n",
    "#print(X_train)\n",
    "#print(y_train)\n",
    "#print(type(X_test))\n",
    "#print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46bbd28f-2f73-4582-9372-c7f207bc3e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train, 'float32')\n",
    "y_train = np.array(y_train, 'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "y_test = np.array(y_test,'float32')\n",
    "\n",
    "#print(type(X_test))\n",
    "#print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4f23e11-ee35-43b0-b0d8-3762b751e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)   \n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
    "\n",
    "y_train= np_utils.to_categorical(y_train, num_classes=7)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=7)\n",
    "\n",
    "#print(X_test)\n",
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6779831a-7527-4974-bef4-80d4ba94a3fd",
   "metadata": {},
   "source": [
    "#VGG16 Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape=(X_train.shape[1:]),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce389fe-7db0-4570-bd1a-a9fbfea52d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 1, 1, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 28679     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,130,567\n",
      "Trainable params: 28,130,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#VGG11 Model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape=(X_train.shape[1:]),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f731a865-814b-4160-9459-26a6b67e5827",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b3d323-1e14-41b0-90e6-d2d3d0884488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "898/898 [==============================] - 377s 419ms/step - loss: 1.7103 - accuracy: 0.3086 - val_loss: 1.5065 - val_accuracy: 0.4191\n",
      "Epoch 2/30\n",
      "898/898 [==============================] - 376s 418ms/step - loss: 1.3960 - accuracy: 0.4585 - val_loss: 1.3074 - val_accuracy: 0.4993\n",
      "Epoch 3/30\n",
      "898/898 [==============================] - 376s 419ms/step - loss: 1.2216 - accuracy: 0.5322 - val_loss: 1.2518 - val_accuracy: 0.5224\n",
      "Epoch 4/30\n",
      "898/898 [==============================] - 377s 419ms/step - loss: 1.0711 - accuracy: 0.5912 - val_loss: 1.1835 - val_accuracy: 0.5561\n",
      "Epoch 5/30\n",
      "898/898 [==============================] - 377s 420ms/step - loss: 0.8969 - accuracy: 0.6686 - val_loss: 1.2015 - val_accuracy: 0.5665\n",
      "Epoch 6/30\n",
      "898/898 [==============================] - 384s 427ms/step - loss: 0.6924 - accuracy: 0.7491 - val_loss: 1.2609 - val_accuracy: 0.5854\n",
      "Epoch 7/30\n",
      "898/898 [==============================] - 417s 465ms/step - loss: 0.4848 - accuracy: 0.8284 - val_loss: 1.4056 - val_accuracy: 0.5807\n",
      "Epoch 8/30\n",
      "898/898 [==============================] - 389s 433ms/step - loss: 0.3372 - accuracy: 0.8818 - val_loss: 1.6222 - val_accuracy: 0.5704\n",
      "Epoch 9/30\n",
      "898/898 [==============================] - 380s 423ms/step - loss: 0.2376 - accuracy: 0.9186 - val_loss: 1.8751 - val_accuracy: 0.5768\n",
      "Epoch 10/30\n",
      "898/898 [==============================] - 380s 423ms/step - loss: 0.1892 - accuracy: 0.9374 - val_loss: 1.9915 - val_accuracy: 0.5829\n",
      "Epoch 11/30\n",
      "898/898 [==============================] - 403s 449ms/step - loss: 0.1597 - accuracy: 0.9476 - val_loss: 2.0781 - val_accuracy: 0.5982\n",
      "Epoch 12/30\n",
      "898/898 [==============================] - 397s 443ms/step - loss: 0.1363 - accuracy: 0.9552 - val_loss: 2.1178 - val_accuracy: 0.5731\n",
      "Epoch 13/30\n",
      "898/898 [==============================] - 399s 445ms/step - loss: 0.1271 - accuracy: 0.9578 - val_loss: 2.0868 - val_accuracy: 0.5829\n",
      "Epoch 14/30\n",
      "898/898 [==============================] - 397s 442ms/step - loss: 0.1150 - accuracy: 0.9612 - val_loss: 2.0867 - val_accuracy: 0.5821\n",
      "Epoch 15/30\n",
      "898/898 [==============================] - 394s 438ms/step - loss: 0.1036 - accuracy: 0.9657 - val_loss: 2.0765 - val_accuracy: 0.5762\n",
      "Epoch 16/30\n",
      "898/898 [==============================] - 403s 449ms/step - loss: 0.0964 - accuracy: 0.9684 - val_loss: 2.2033 - val_accuracy: 0.5854\n",
      "Epoch 17/30\n",
      "898/898 [==============================] - 402s 448ms/step - loss: 0.0921 - accuracy: 0.9709 - val_loss: 2.1892 - val_accuracy: 0.5921\n",
      "Epoch 18/30\n",
      "898/898 [==============================] - 401s 447ms/step - loss: 0.0971 - accuracy: 0.9675 - val_loss: 2.2313 - val_accuracy: 0.5910\n",
      "Epoch 19/30\n",
      "898/898 [==============================] - 395s 440ms/step - loss: 0.0806 - accuracy: 0.9735 - val_loss: 2.3268 - val_accuracy: 0.5848\n",
      "Epoch 20/30\n",
      "898/898 [==============================] - 400s 445ms/step - loss: 0.0816 - accuracy: 0.9739 - val_loss: 2.2319 - val_accuracy: 0.5915\n",
      "Epoch 21/30\n",
      "898/898 [==============================] - 391s 435ms/step - loss: 0.0821 - accuracy: 0.9732 - val_loss: 2.0797 - val_accuracy: 0.5851\n",
      "Epoch 22/30\n",
      "898/898 [==============================] - 382s 425ms/step - loss: 0.0712 - accuracy: 0.9769 - val_loss: 2.3863 - val_accuracy: 0.5904\n",
      "Epoch 23/30\n",
      "898/898 [==============================] - 383s 426ms/step - loss: 0.0793 - accuracy: 0.9742 - val_loss: 2.1213 - val_accuracy: 0.5940\n",
      "Epoch 24/30\n",
      "898/898 [==============================] - 379s 422ms/step - loss: 0.0694 - accuracy: 0.9772 - val_loss: 2.3762 - val_accuracy: 0.5818\n",
      "Epoch 25/30\n",
      "898/898 [==============================] - 381s 424ms/step - loss: 0.0665 - accuracy: 0.9767 - val_loss: 2.2655 - val_accuracy: 0.5899\n",
      "Epoch 26/30\n",
      "898/898 [==============================] - 389s 434ms/step - loss: 0.0725 - accuracy: 0.9759 - val_loss: 2.4340 - val_accuracy: 0.5834\n",
      "Epoch 27/30\n",
      "898/898 [==============================] - 416s 464ms/step - loss: 0.0634 - accuracy: 0.9801 - val_loss: 2.4221 - val_accuracy: 0.5868\n",
      "Epoch 28/30\n",
      "898/898 [==============================] - 403s 448ms/step - loss: 0.0593 - accuracy: 0.9796 - val_loss: 2.4447 - val_accuracy: 0.5848\n",
      "Epoch 29/30\n",
      "898/898 [==============================] - 406s 452ms/step - loss: 0.0631 - accuracy: 0.9796 - val_loss: 2.5737 - val_accuracy: 0.5896\n",
      "Epoch 30/30\n",
      "898/898 [==============================] - 407s 454ms/step - loss: 0.0570 - accuracy: 0.9812 - val_loss: 2.5270 - val_accuracy: 0.5818\n"
     ]
    }
   ],
   "source": [
    "emotion_model_info = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size= 32,\n",
    "    epochs= 30,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test),\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1570cc1-eed6-44f8-9ecf-993c2d0ae0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "  model.save_weights(\"model.h5\")\n",
    "\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
